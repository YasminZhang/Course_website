
## Overview
This course introduces the foundational concepts and algorithms of machine learning and deep learning. The goal of this course is to endow the student with a) a solid understanding of the foundational concepts of machine learning, and b) morden machine learning techniques such as deep learning. Topics to be covered include empirical risk minimization, PAC learning, Agnostic PAC learning, perceptron, linear regression, boosting, stochastic gradient descent, support vector machines, multi-layer perceptron, convolutional neural networks, recurrent neural networks, attention mechanism. Slides and homework assignments will be released on this website. Homework solutions will only be released on Bruinlearn.

## Prerequisites
Calculus, linear algebra, probability and statistics, and Python programming.

## Textbook
- [SSBD] Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algorithms. Cambridge University Press, 2014.
- [ZLLS] Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola, Dive into Deep Learning. 

## Programming Language
Python, Pytorch

## Logistics
<!--University of California, Los Angeles  -->
- Time: **Monday and Wednesday 2:00PM - 3:50PM**
- Location: **DODD 147**  
- Instructor: [Quanquan Gu](http://web.cs.ucla.edu/~qgu/) (Email: qgu at cs dot ucla dot edu)   
- Teaching Assistant: 
  - Zixiang Chen, Section 1A (Email: chenzx19 at cs dot ucla dot edu)
  - Jiafan He, Section 1B (Email: jiafanhe19 at g dot ucla dot edu)
  - Lucas Tecot, Section 1C (Email: lucastecot at gmail dot com)
   
- Office hours: 
    - The instructor's office hour is Thursday 9:00am-10:00am, EVI 382. 
    - The TA's office hour is 
      - Zixiang Chen, Monday 10am-12pm, Boelter 3256S-A
      - Jiafan He, Thursday 10am-12pm, Boelter 3256S-F
      - Lucas Tecot, Wednesday 10am-12pm, Boelter
  
- Course Website: [https://uclaml.github.io/CS260-Fall2022/](https://uclaml.github.io/CS260-Fall2022/)
- Course Forum: [https://piazza.com/ucla/fall2022/cs260/home](piazza.com/ucla/fall2021/cs260/home)
(If you haven’t already, [sign up here](https://piazza.com/ucla/fall2022/cs260).)

## Grading Policy
 
Grades will be computed based on the following factors:

- Homework 35%
- Quiz 5%
- Midterm 30%
- Final Project 30%

## Schedule

| # | Date   |      Topics      |  Reading | Homework |
|---- | ----------|-------------|------|---|
| 1 | 9/26 | Introduction ([slides](https://www.dropbox.com/s/umb5cj22wktqxwq/Lecture1.pdf?dl=0))([slides_annotated](https://www.dropbox.com/s/qsx5ybu668zgsc3/Lecture1_annotated.pdf?dl=0)) | Chapter 1, 2.1 of [SSBD] |  |
| 2 | 9/28 | Empirical Risk Minimization, PAC Learning ([slides](https://www.dropbox.com/s/oz92oe6w24x7q1a/Lecture2.pdf?dl=0))([slides_annotated](https://www.dropbox.com/s/0cc4m715l5pzjrr/Lecture2_annotated.pdf?dl=0)) | Chapter 2 of [SSBD]| [HW1 Out](https://www.dropbox.com/s/g31899cgztwdfov/HW1.pdf?dl=0)|
||9/30| TA Session Week 1 ([1A slides](https://www.dropbox.com/s/xt9krm4s4qjy4h8/Slides%28discussion1A%29.pdf?dl=0))([1B slides](https://www.dropbox.com/s/520b4ot1espxcq0/week1%20discussion%201B.pdf?dl=0))([1C slides](https://www.dropbox.com/s/sn67z1e46ab9zrt/week1.pdf?dl=0))|||
| 3 | 10/3 | Agnostic PAC Learning ([slides](https://www.dropbox.com/s/b1x1c9sdse2ieam/Lecture3.pdf?dl=0))([slides_annotated](https://www.dropbox.com/s/kwj44enab7l6omi/Lecture3_annotated.pdf?dl=0))| Chapter 3 of [SSBD] | |
| 4 | 10/5 | Bias-Complexity Tradeoff ([slides](https://www.dropbox.com/s/v6i1cay016gr2ju/Lecture5.pdf?dl=0))([slides_annotated](https://www.dropbox.com/s/a18ybz1o1g5zhgm/Lecture5_annotated.pdf?dl=0)) | Chapter 5, 11 of [SSBD] |  |
|| 10/7 | TA Session Week 2 ([1A slides](https://www.dropbox.com/s/5bp737g3g44hj8j/discussion1Aweek2.pdf?dl=0))([1B slides](https://www.dropbox.com/s/jiefamzvw022t90/week2.pdf?dl=0))([1C slides](https://www.dropbox.com/s/4o5pk11jo0wy3ev/week2.pdf?dl=0))|||
| 5 | 10/10 | Perceptron/Linear regression ([slides](https://www.dropbox.com/s/188xqq39z3twhy2/Lecture8.pdf?dl=0))([slides_annotated](https://www.dropbox.com/s/7mns5vnoyr6nszc/Lecture7_annotated.pdf?dl=0)) | Chapter 9 of [SSBD] | HW1 Due, [HW2 Out](https://www.dropbox.com/s/uocco8rr9rcxilu/HW2.pdf?dl=0) |
| 6 | 10/12 | Boosting ([slides](https://www.dropbox.com/s/znevp3vo3glsp3p/Lecture11.pdf?dl=0))([slides annotated](https://www.dropbox.com/s/bcdfih6y9i7ttbc/Lecture11_annotated.pdf?dl=0)) | Chapter 10 of [SSBD] | |
||10/14| TA Session Week 3 ([1A slides](https://www.dropbox.com/s/z32s1341e1u840q/discussion1A%20slides%28week3%29.pdf?dl=0))([1B slides](https://www.dropbox.com/s/8x1kcfxcn17x5ms/week3.pdf?dl=0))([1C slides](https://www.dropbox.com/s/y69l9ewwbevhj1d/week3.pdf?dl=0))|||
| 7 | 10/17 | Convex Learning and SGD ([slides](https://www.dropbox.com/s/5ljjnj12v04m90b/Lecture12.pdf?dl=0))([slides annotated](https://www.dropbox.com/s/u93rssag5j3hbc5/Lecture12_annotated.pdf?dl=0)) | Chapter 12, 14 of [SSBD] |  |
| 8 | 10/19 | AI4Database | Quest lecture | HW2 Due, [HW3 Out](https://www.dropbox.com/s/rs1rtw7tf7lxwlk/homework3.zip?dl=0) |
||10/21| TA Session Week 4 ([1A slides](https://www.dropbox.com/s/oihdcz1z3vs2mxa/CS_260_TA_Session%20week4.pdf?dl=0))([1B slides](https://www.dropbox.com/s/2uafin21tcbv3uu/week4.pdf?dl=0))([1C slides](https://www.dropbox.com/s/65nffmshlr5omyp/week4.pdf?dl=0))|||
| 9 | 10/24 | Support Vector Machines ([slides](https://www.dropbox.com/s/5ljjnj12v04m90b/Lecture12.pdf?dl=0)) ([slides annotated](https://www.dropbox.com/s/u93rssag5j3hbc5/Lecture12_annotated.pdf?dl=0)) | Chapter 15 of [SSBD] |  |
| 10 | 10/26 | Kernel Methods ([slides](https://www.dropbox.com/s/0zuw2gvug8os3ds/Lecture14.pdf?dl=0)) ([slides annotated](https://www.dropbox.com/s/yw922y2ovx5zdub/Lecture14_annotated.pdf?dl=0))| Chapter 16 of [SSBD] | HW3 Due, [HW4 Out](https://www.dropbox.com/s/mh54q0q98nqu5v8/CS260_HW4.pdf?dl=0) |
|| 10/28 | TA Session Week 5 ([1A slides](https://www.dropbox.com/s/csdogq3bl2w3wvr/week5.pdf?dl=0))([1B slides](https://www.dropbox.com/s/mea55w6r56gd5xv/week5.pdf?dl=0))([1C slides](https://www.dropbox.com/s/rt74nchcvmdfty4/week5.pdf?dl=0))|||
|  | 10/31 | Midterm | Chapter 15 |  |
| 11 | 11/2 | Multi-layer Perceptron I | Chapter 4 and 5 of [ZLLS] |  |
||11/4| TA Session Week 6 ([1A slides](https://www.dropbox.com/home/CS260%20Fall%202021/21Fall-Discussion/1A?preview=week6.pdf))([1B slides](https://www.dropbox.com/s/up0whiz2o8m0jg1/week61B.pdf?dl=0)) |||
| 12 | 11/7 | Multi-layer Perceptron  II | Chapter 4 and 5 of [ZLLS] | HW4 Due, [HW5 Out](https://www.dropbox.com/s/xq442mow3vybp96/HW5.pdf?dl=0) |
| 13 | 11/9 | Covolutional Neural Networks I | Chapter 7 of [ZLLS] | |
||11/11| TA Session Week7 ([1A slides](https://www.dropbox.com/s/qyb7ojm2eekdwvg/week7.pdf?dl=0))([1B slides](https://www.dropbox.com/s/374l2cnxtruh9ln/week7.pdf?dl=0))([1C slides](https://www.dropbox.com/s/p4h8fubjyux064c/week7.pdf?dl=0))|||
| 14 | 11/14 | Covolutional Neural Networks II | Chapter 8 of [ZLLS] | |
| 15 | 11/16 | Recurrent Neural Networks I | Chapter 9 of [ZLLS] | HW5 Due, [HW6 Out](https://www.dropbox.com/s/xq442mow3vybp96/HW5.pdf?dl=0)|
||11/18 | TA Session Week 8 ([1A slides](https://www.dropbox.com/s/blfxztrcy8kd8h5/week8.pdf?dl=0))([1B slides](https://www.dropbox.com/s/bijb4ev7gahc0li/week%208.pdf?dl=0))([1C slides](https://www.dropbox.com/s/kdzihhzxcw4tncg/week8.pdf?dl=0))|||
| 16 | 11/21 | Recurrent Neural Networks II | Chapter 10 of [ZLLS] | |
||11/23| Thanksgiving holidays|||
|17  | 11/28 | Attention Mechanisms | Chapter 11 of [ZLLS] | HW6 Due|
||12/2| TA Session Week10 ([1A slides](https://www.dropbox.com/s/nujqsnib0j3j9pw/week10.pdf?dl=0))([1B slides](https://www.dropbox.com/s/th42birwuuiubl8/week101B.pdf?dl=0))([1C slides](https://www.dropbox.com/s/cqqb2mwilpq300q/week10.pdf?dl=0)) | |  |
| | 12/8 | Final Project Presentation | |  |
| | 12/12 | | | Project Report/Slides Due |

## Academic Integrity Policy
Students are encouraged to read the [UCLA Student Conduct Code](https://www.deanofstudents.ucla.edu/Individual-Student-Code) for Academic Integrity. 

## Homework
There will be about 5 homework assignments during the semester as we cover the corresponding material. Homework consists of both mathematical derivation, algorithm analysis and programming. Homework is required to be written in Latex. Latex homework template can be found [here](https://www.dropbox.com/s/cbfagod4yq5zsdg/CS260-hw-template.zip?dl=0). The lowest homework score will be dropped for you.

Unless otherwise indicated, you may talk to other students about the homework problems but each student must hand in their own answers and write their own code in the programming part. You also must indicate on each homework with whom you collaborated and cite any other sources you use including Internet sites. Students cannot use old solution sets for this class or solution manual to the textbook under any circumstances.

Homework assignments will be submitted through Gradescope. You should have received an invite to Gradescope after you get enrolled in this class. Login via the invite, and submit the homework assignments on time. 

Please submit your homework on time. Homework is worth full credit before the due date. It is worth zero credit after the due date.

## Exam
There will be one midterm. The exam is a take-home, 24-hours, open-book exam. If you need a makeup exam, please email us by Nov 1st.

## Quiz
There will be 6 in-class pop-up quiz for the purpose of reviewing the newly learned concepts. The quizzes are closed book and closed notes. No electronic aids or cheat sheets are allowed. We will drop the lowest quiz score for you.

## Project
Students are required to do a project in this class. The goal of the course project is to provide the students an opportunity to explore research directions in optimization or machine learning. Therefore, the project should be related to the course content. An expected project consists of
• A novel and sound solution to an interesting problem
• Comprehensive literature review and discussion
• Thorough theoretical/experimental evaluation and comparisons with existing approaches

The best outcome of the project is a manuscript that is publishable in major machine learning conferences (COLT, ICML, NeurIPS, ICLR, AISTATS, UAI etc.) or journals (Journal of Machine Learning Research, Machine Learning).

Instruction can be found [here](https://www.dropbox.com/s/iq6ctshs91ea3ok/Instruction.pdf?dl=0), and template for proposal and final report can be found [here](https://www.dropbox.com/s/9i5kjaibbw58ghl/template.zip?dl=0).

Please refer to [syllabus](https://www.dropbox.com/s/89u56o3rzr54asv/syllabus_CS260.pdf?dl=0) for more details.

